{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><br>\n",
    "    <h2>Week 7_Unstructured Data & Regex (Template)</h2> <br>\n",
    "    <p>Follow the steps below to process one .txt file, and then two or three .txt files without using the functionality of NLTK. You may though use NLTK once to import the predefined stopwords list to clean your files.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: coral\">\n",
    "<h2>Part 1</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Open and read one text file</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and then read in the .txt file of your choosing. You may use one of the .txt files provided in Week 6.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Clean the text file</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation marks with .replace() and turn the text to lower cases with .lower()\n",
    "\n",
    "\n",
    "\n",
    "# Print out the cleaned text. Iterate the cleaning part until your text is ready to analyze.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Tokenize the text</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the cleaned text with .split().\n",
    "\n",
    "\n",
    "# Print it out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Remove stop words from the text list</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from the list of strings that you should have received after tokenization.\n",
    "# You may use the functionality of NLTK in this part.\n",
    "# Either import stopwords from the corpus sub-library of NLTK or create you custom list.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords by matching the words in the tokenized list against the list of stop words.\n",
    "# Write a for-loop or a list comprehension construct.\n",
    "\n",
    "\n",
    "        \n",
    "# Print out the cleaned list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Extract word frequencies</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may use the Counter method from the collections module.\n",
    "# Alternatively, you may write a loop for this task. \n",
    "\n",
    "\n",
    "\n",
    "# Pass the cleaned list of word strings to the Counter() function.\n",
    "\n",
    "\n",
    "# Print out the variable in which you've stored the data. It should return a dictionary \n",
    "# where each word should be in the key's position, and its frequency count should be in the value's position.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Convert the frequency dictionary to a list</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the frequency dictionary into a list with the .items() methods before its conversion to DataFrame.\n",
    "# Use a list comprehension construct.\n",
    "\n",
    "\n",
    "\n",
    "#Print out the resulting nested list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Convert the list to a DataFrame</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the nested list into a pandas' DataFrame.\n",
    "\n",
    "\n",
    "\n",
    "# Print out the DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Generate a wordcloud</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wordcloud module if you already installed it on your machine.\n",
    "\n",
    "# Import matplotlib's sub-library pyplot. \n",
    "\n",
    "\n",
    "# Declare the magic line for inline visuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice off only the values of the Words column (index position 0). \n",
    "# Also, pass the sliced off values as an argument to str().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image with WordCloud().generate():\n",
    "\n",
    "\n",
    "# Display the generated image with the pyplot's method .imshow():\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: coral\">\n",
    "<h2>Part 2</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Create a list of multiple text files</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of several .txt files and store it in a variable.\n",
    "# Make sure that all the texts belong to one author.\n",
    "\n",
    "\n",
    "\n",
    "# Print out the variable to which you assigned the list of .txt files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Process the list of text files</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a loop that iterates over each .txt file in the file list, and \n",
    "# opens, reads, cleans (punctuation marks, lowercases), tokenizes, removes stopwords, extracts frequencies, \n",
    "# converts a frequency dictionary into a nested list, AND appends that list to an empty list, which you should have\n",
    "# initialized before writing this loop.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the empty list which should return the nested lists of words and their counts per each text file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Flatten the nested list</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the multidimensional (nested) list to a list with fewer dimensions\n",
    "# You'll need the list() function, and the chain object and the .from_iterable() method imported from itertools \n",
    "\n",
    "\n",
    "\n",
    "# Print out the flattened list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Convert the flattened list to a DataFrame</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the flattened frequency list to a DataFrame.\n",
    "\n",
    "\n",
    "# Print out the DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Generate a wordcloud</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice off the values from the Words column of the DataFrame and pass them as an argument to str()\n",
    "\n",
    "\n",
    "# Generate a word cloud image with WordCloud().generate():\n",
    "\n",
    "\n",
    "# Display the generated image with the pyplot's method .imshow():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: coral\">\n",
    "<h2>Part 3</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h3>Match 5 Regex patterns in multiple text files</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the re module.\n",
    "\n",
    "\n",
    "# Write a for-loop to iterate through each text file in the file list to match some patterns of language use.\n",
    "# You may need to scrutinize the texts or word frequencies per each text to decide what you want to match.\n",
    "\n",
    "\n",
    "# Store the matched patterns in the empty list 'pattern1' and print it out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write another loop to iterate the file list and identify another pattern.\n",
    "\n",
    "\n",
    "# Store the matched patterns in the empty list 'pattern2' and print it out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write another loop to iterate the file list and identify another pattern.\n",
    "\n",
    "\n",
    "# Store the matched patterns in the empty list 'pattern3' and print it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write another loop to iterate the file list and identify another pattern.\n",
    "\n",
    "\n",
    "# Store the matched patterns in the empty list 'pattern4' and print it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write another loop to iterate the file list and identify another pattern.\n",
    "\n",
    "\n",
    "# Store the matched patterns in the empty list 'pattern5' and print it out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h2>Homework 7</h2><br>\n",
    "<p>\n",
    "If you don't finish all the steps in class, it will be your homework to complete this task in this file on your own. If your group completes the assignment in class, then choose another set of texts to process, as above, for your homework.</p>\n",
    "<p>\n",
    "<p>Submit the completed Jupyter Notebook along with .txt files zipped in 'homework7.zip' via the designated area called 'Homework 7' under Week 7 on KEATS by 4pm on <b>Wed 2nd December 2020</b>.</p><br>    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
