{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><br>\n",
    "    <h2>Week 8_Scraping Web Data (Template)</h2> <br>\n",
    "    <p>Follow the steps below to scrape off web data from <a href=\"https://www.worldwildlife.org/species/directory#\">the website on worldwildlife</a>.</p><br>\n",
    "    <p>In this webinar, we'll revise the code of slicing, loops, user-defined functions, creating and cleaning DataFrames, and visualization of categorical data.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: coral\">\n",
    "<h2>Part 1: Scrape and organize data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests and BeautifulSoup libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the connection with the webpage by sending a GET request to its server\n",
    "\n",
    "\n",
    "\n",
    "# Check whether the connection has been established\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the content of the HTML page\n",
    "\n",
    "\n",
    "# Print out the variable in which you've stored the HTML content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML page with a parser of your choosing\n",
    "\n",
    "\n",
    "# Print out the variable in which you've stored the parsed HTML page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape off all three columns of data. You will need to inspect the <table> and <tbody> elements \n",
    "# Note that you need to find the html element that is closest to the text that you want to scrape\n",
    "# <table> and <tbody> are the wrapper elements that do not contain the immediate text/content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text only with the .text property and store it in a list either \n",
    "# with a for-loop or a list comprehension construct\n",
    "\n",
    "\n",
    "# Print out the scraped data\n",
    "# What do you see? Does it need any sorting out?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and sift out 'Common Names' into one list, then 'Scientific Names' into another list, \n",
    "# and 'Conservation Status' into a third list\n",
    "# Alternatively, you may want to sift out three types of variables into lists by using loops\n",
    "# Slice off only the Common Names from the list created above and print out the variable to see the results\n",
    "# Use the double colon :: to set the slicer to jump the items in the list created above by three, and \n",
    "# as it jumps by three, it should clice off items in index position[0], e.g. name[1::3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice off only the Scientific Names from the pd.Series created above and print out the variable to see the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice off only the Conservation Status from the pd.Series created above & print out the variable to see the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all three data variables into one DataFrame consisting of three columns\n",
    "# if you created three lists above, as suggested, then use .DataFrame(list(zip(list1, list2, list3)), columns=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows that contain empty cells and print out the updated dataset\n",
    "# Note that empty cells are not filled in with 'NaN', so first create a variable that converts 'NaN' strings to\n",
    "# floats because pandas take NaN as a float\n",
    "\n",
    "\n",
    "\n",
    "# Then use .replace(\"\", variable) to replace empty cells with 'NaN' values\n",
    "\n",
    "\n",
    "# Finally, use .dropna(subset=[Name of the third column]) to remove rows if that particular column contains \n",
    "# NaN or missing values. Other columns also have missing values but we can keep those for now\n",
    "# because later we'll be visualizing only the conservation variables present in the third column \n",
    "\n",
    "\n",
    "\n",
    "# Print out the variable in which you've stored the updated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .reset_index(drop=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: coral\">\n",
    "<h2>Part 2: Visualize data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the metadata about the categorical data in the 'Conservation Status' column with .value_counts()\n",
    "\n",
    "\n",
    "# What type of categories and how many do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract index and values with .index and .values properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of conservation status as a bar chart\n",
    "\n",
    "# Define a custom list of colors\n",
    "\n",
    "\n",
    "\n",
    "# Import numpy because you will need its .arange() method to create as many bars as there are data categories\n",
    "# Import .pyplot and declare the magic line for inline visualization\n",
    "\n",
    "\n",
    "\n",
    "# Plot the categorical data as bars and save it with .savefig() as an image file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: coral\">\n",
    "<h2>Part 3: Scrape data off two pages</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two pages of the data on animals and their conservation status. We've scraped \n",
    "# Create a list of those two urls. Note that you need to enter them as strings, hence use double or single quotes\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each url link with a loop to scrape data off both links & to create a single DataFrame as above\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to visualize the distribution of conserv. status scraped off both webpages and to save\n",
    "# the visual as an image file in the directory\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the second DataFrame that contains data from both webpages as a .csv file in the directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h2>Homework 8</h2><br>\n",
    "<p>\n",
    "If you don't finish all the steps in class, it will be your homework to complete this task in this file on your own. If your group completes the assignment in class, then choose another webpage(s) to process, as above, for your homework.</p>\n",
    "<p>\n",
    "<p>Submit the completed Jupyter Notebook as 'homework8.ipynb' via the designated area called 'Homework 8' under Week 8 on KEATS by 4pm on <b>Thursday 10th December 2020</b>.</p><br>    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
